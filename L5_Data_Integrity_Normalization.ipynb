{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L5_Data_Integrity_Normalization.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"11MBPducEj0HgT0u-nrCE60AvHJQnPR3y","authorship_tag":"ABX9TyNqceMU3rQsm8+Igow2+kI+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5rHzwUorF5ab"},"source":["<img src=\"https://github.com/christopherhuntley/BUAN6510/blob/master/img/Dolan.png?raw=true\" width=\"180px\" align=\"right\">\n","\n","# **BUAN 6510**\n","# **Lesson 5: Table Design and Normalization** \n","_The science of bulletproofing your tables._\n","\n","## **Learning Objectives**\n","### **Theory / Be able to explain ...**\n","- Tradeoffs that every designer makes\n","- Table normalization and normal forms\n","- Table denormalization and when to use it\n"," \n","\n","### **Skills / Know how to ...**\n","- Break a large table into normalized tables\n","- Use relational notation to describe table schema\n","- Detect when a choice of keys will potentially corrupt data\n","- Denormalize data in SQL to suit the needs of data analysts\n","\n","--------\n","## **LESSON 5 HIGHLIGHTS**"]},{"cell_type":"code","metadata":{"id":"I95WVwkCnTJF","colab":{"base_uri":"https://localhost:8080/","height":579},"cellView":"form","executionInfo":{"status":"ok","timestamp":1611015176143,"user_tz":300,"elapsed":503,"user":{"displayName":"Christopher Huntley","photoUrl":"","userId":"11069151036176747256"}},"outputId":"300d60fd-f79f-4fac-ac18-83b70416459a"},"source":["#@title Run this cell if video does not appear\n","%%html\n","<div style=\"max-width:1000px\">\n","  <div style=\"position: relative;padding-bottom: 56.25%;height: 0;\">\n","    <iframe style=\"position: absolute;top: 0;left: 0;width: 100%;height: 100%;\" rel=\"0\" modestbranding=\"1\"  src=\"https://www.youtube.com/embed/rsCrjQck_jQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n","  </div>\n","</div>"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div style=\"max-width:1000px\">\n","  <div style=\"position: relative;padding-bottom: 56.25%;height: 0;\">\n","    <iframe style=\"position: absolute;top: 0;left: 0;width: 100%;height: 100%;\" rel=\"0\" modestbranding=\"1\"  src=\"https://www.youtube.com/embed/rsCrjQck_jQ\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n","  </div>\n","</div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"BtUFh7tdEYdh"},"source":["### **Run this boilerplate code before continuing on.** \n"," "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"3fTBygBpAj2N","executionInfo":{"status":"ok","timestamp":1610465884618,"user_tz":300,"elapsed":11935,"user":{"displayName":"Christopher Huntley","photoUrl":"","userId":"11069151036176747256"}},"outputId":"d245236f-e3c9-4866-ef39-4ddf1ca21004"},"source":["# Load %%sql magic\n","%load_ext sql\n","\n","# Standard Imports\n","import sqlite3\n","import pandas as pd\n","\n","# Install the Python to MySQL DBI connector\n","!pip install pymysql\n","\n","%sql mysql+pymysql://buan6510student:buan6510@database-01202.c55qjoeogr2p.us-east-2.rds.amazonaws.com/lahman2016"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pymysql\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/52/a115fe175028b058df353c5a3d5290b71514a83f67078a6482cff24d6137/PyMySQL-1.0.2-py3-none-any.whl (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \n","\u001b[?25hInstalling collected packages: pymysql\n","Successfully installed pymysql-1.0.2\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Connected: buan6510student@lahman2016'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"rCFhbs0BBTN9"},"source":["**Rerun this code as needed to keep your software up to date and database connection fresh.**  "]},{"cell_type":"markdown","metadata":{"id":"aVKAjKlGheMm"},"source":["---\n","## **BIG PICTURE: Why programmers suck at database design**\n","In some ways, programming is the most arrogant profession of all. Software is inherently malleable in ways that nothing else can possibly be. Like science fiction writers, programmers can alter the laws of physics to suit whatever the needs are at the time. However, unlike fiction writers, programmers can go a step further by building *and running* the universes they design. Software is not a simulation or a movie, it is the very embodiment of whatever the programmer wants it to be. That is real power, just in a very narrow universe. \n","\n","These days most programmers learn the craft by building *apps* of one sort or another. An app is all about process, handling whatever actions the user chooses. If there is data involved then it rarely exists beyond a single use of the app, perhaps as cache or maybe a message to be sent to a server somewhere in the cloud. Outside of this scope, the app programmer generally does not really care. It's all beyond their control anyway. \n","\n","It is in the cloud that the persistent part of the software exists. If data is to be stored and shared among many users then it is a *systems* programmer who will design and build that necessary middleware and data repositories. For these programmers the world is less about the dynamics of the app and more about the permanent structures needed to keep it running. \n","\n","There are some programmers, who like to call themselves *full stack developers*, that do both frontend app and the backend server development. However, if you dig even a little bit into their knowledge base, you will likely find that they are 80% frontend and 20% backend. They know just enough about the backend to keep the apps running but don't really like doing it very much. Instead, they are always looking for shortcuts so they can make the visible part of the app that much nicer. \n","\n","The same kind of milieu is common in data science, where the sexy frontend stuff that everybody sees is the models and the visuals. Like the apps developers, they see data management as a chore. To them everything is just better if each project has a massive dataset (table) that they can build models from. If there are any bugs in the data then they will just program around them. Why not? The tools make it easy to do so. \n","\n","Where does this leave us? In a world where fewer and fewer programmers *really* understand database design. There just isn't enough to get excited about when one can get so much instant gratification from a UI tweak or running a fancy new machine learning algorithm. Honestly, who can blame them? Nobody is going to pat them on the back for getting the backend right but everybody will exclaim in excitement when an analytical model unearths a previously unknown insight and then distills it down to *just the right story*. \n","\n","That said, always be on the lookout for data errors that can't be programmed around. Sometimes they make the difference between being right and dead wrong. \n","\n","In this lesson we will learn about table design, starting with the tradeoffs a designer invariably has to make before moving on to the normatively *correct* techniques of normalization and table decomposition. We will conclude with a discussion of when to throw out correctness in favor of convenience, speed, or analyst preferences. "]},{"cell_type":"markdown","metadata":{"id":"X5h41XeBBWcK"},"source":[" ---\n","## **Design Tradeoffs**\n","### **The Eternal Dilemma**\n","\n","Design is about making decisions. If we make the right decisions, then the right systems get built and everybody is blissfully happy. We might not get the credit but people are happy nonetheless. If we make the wrong decisions then everybody is upset *at us*. \n","\n","So what is the right way to design a system? Well, if that were answerable in a paragraph, then it wouldn't be design. We have to consider what is being asked of the system, what solutions are available, and what we can afford. In other words, it comes down to tradeoffs and priorities. \n","\n","We will now take a look at a few eternal data design priorities, in what should be increasing importance for most applications. However, your mileage may vary depending on the needs at the time. \n","\n","### **Minimizing Space**\n","In the old days before big data, storage was often the most expensive part of a computer system. Programmers would do just about any amount of programming to avoid buying new storage hardware. They would literally count characters to minimize the number of bytes a given file required on disk. \n","\n","To this end, they came up with some tricks that often shaved off kilobytes without having to resort to file compression. A few examples:\n","- Repeating fields, where each line of file only recorded what was different from the line above.\n","- Cryptic codes in place of long strings of text. Often they were hardwired into the programs, working like magic incantations when used by people in the know. \n","- Overloading fields so that multiple facts could be stored in one field. \n","\n","You can see this same kind of thinking today in the messages passed between the front end app and a server. However, network bandwidth is becoming so plentiful that even this last bastion of space efficiency is just not important to worry about. \n","\n","Space is cheap and getting cheaper. \n","\n","### **Maximizing Calculation Speed**\n","Along the same lines as with space, raw speed has historically been prioritized over correctness. Long ago it was because computers were so slow. These days it is because we ask so much more of our computer systems. If we can shave 5% of the computing time off a given operation that will be performed billions of times, then it is well worth it to do so.\n","\n","Relevant techniques for raw speed include:\n","- Precomputing whatever can be done in advance, even when it swells storage with redundant data.\n","- Approximating results whenever 100% fidelity is not strictly necessary.\n","- Locating data closer to each user, even when it means some data will be out of sync with others\n","\n","Of course, computers are getting faster and faster. However, expect this trend to continue as demands for raw speed will likely increase faster than we can build bigger and faster hardware.  \n","\n","### **Maximizing Coherency**\n","Coherency is the ability to make sense of the data. Do all the facts fit together to tell coherent stories? Is each fact expressed in the best possible way? \n","\n","Generally, data coherency has been the domain of data modelers, who are more concerned with the stories than the data itself:\n","- What are the entities being tracked?\n","- What data is collected about each one? \n","- How do the entities relate to each other? \n","\n","These sorts of questions never get old. They are focused on the same things as the app developer and the data scientists. \n","\n","We will touch on some of these questions in this lesson, then devote the bulk of Lesson 6 to entity relationship modeling. \n","\n","### **Minimizing Risk of Data Corruption**\n","Data integrity is an essential quality that never gets old. It is literally seeking to put the truth (and only the truth) into our databases. It is getting harder and harder to achieve, however. \n","\n","Big data is ugly data. It often comes in corrupted, forcing the database system to clean it up before it can be stored. If the system is going to do that then it needs to have a goal, a definition of what *correct* and *clean* are. If data can't be fixed then the system should reject it rather than accept a lie as the truth. \n","\n","It is this last design priority that is at the heart of table design and normalization. If we design our tables so that they follow a few (not-so-easy) rules, then we can avoid the vast majority of data corruption errors or, as we will call them, **data anomalies**. "]},{"cell_type":"markdown","metadata":{"id":"NekcmKiCsxQm"},"source":["---\n","## **Relational Notation**\n","\n","In order to design tables we need concise language to describe them. We have already seen ER diagrams (and will again in Lesson 6), but often we don't want or need diagramming software, especially when we're just getting started and table names, columns, etc. may change. For that we use **relational notation**.\n","\n","In this lesson we will adopt the following convention:  \n","`Table_Name(`**`primary, key, columns`**, `non, key columns,` <u>`foreign, key, columns`</u>`)`\n","\n","- The table name uses `Initial_Caps`.\n","- Columns are listed `(`inside parentheses`)` immediately after the table name.\n","- Primary key columns **`are in bold`**; on a whiteboard we might use an alternate color instead.\n","- Nonkey columns are in `regular text`.\n","- Foreign key columns are <u>`underlined`</u>.\n","\n","With this notation in place we can design dozens of tables at a time without worrying too much about details that can be worked out later. \n","\n","In the Movies Tonight case (which we'll start later in this lesson) we will be designing the following tables, starting with a messy spreadsheet:\n","- `Artist(`**`artistID`**, `name)`\n","- `Movie(`**`movieID`**, `title,rating)`\n","- `Theater(`**`theaterID`**, `name, location, phone)`\n","- `Credit(`**`showId`**, `ccode`, <u>`movieID`</u>,<u>`artistID`</u>`)`\n","- `Show(`**`showId`**, `showtime`, <u>`movieID`</u>,<u>`theaterID`</u>`)`\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MSHIE5GMVm6M"},"source":["---\n","## **Normalization**\n","\n","**Normalization** is a process of breaking large, messy tables into smaller, more coherent ones.\n","\n",">The term \"normalization\" actually has a bit of political history behind it. At about the time that researchers were formalizing the rules of normalization in the early 1970s, the US was *normalizing relations* with China. The two countries were going to have to adopt a few conventions in order to work together. Why not apply the same term to making tables cohabitate nicely within a database?\n","\n","The normalization process has four goals:\n","- Each table represents a single subject.\n","- No data item will be unnecessarily stored in more than one table.\n","- All non-prime (not PK) attributes in a table are dependent on the PK (and only the PK).\n","- Each table is devoid of insertion, update, and deletion **anomalies**.\n","\n","These rules are actually a bit stricter than the **coherent relation** rules we learned in Lesson 4. In other words, normalization always produces coherent relations but we don't always need to *fully* normalize in order to have coherent relations. Thus, the normalization process defines **degrees of normalization** called **normal forms**:\n","- 1NF\n","- 2NF\n","- 3NF\n","- BCNF\n","- ...\n","\n","Each normal form builds on the ones before it, applying ever stricter conditions that have to be satisfied.\n","\n","We will need a little bit more math before we get started with the normal forms. \n","\n","### **Functional Dependencies**\n","A **functional dependency** within a table is when a group of columns can be used to *look up* or *derive* the values of another group of columns. \n","\n","We write out dependencies as mappings like the ones we used in lesson 4:  \n","**determinants $\\rightarrow$ dependents**\n","\n","Given the values of the **determinant** columns on the left, we can deduce the value of the **dependent** columns on the right. Or, more concisely, the determinants *determine* the dependents.\n","\n","The most obvious functional dependency derives from the row number within a table. Given the row number we can simply look up the values in the columns. \n","\n","Let's say we have a table like this:  \n","`Student(`**`studentID`**,`name, dorm, room, fee)`\n","\n","Then we can pretty easily deduce a few dependencies like\n","- `studentID` $\\rightarrow$  `name`\n","- `studentID` $\\rightarrow$  `(dorm, room, fee)`\n","- `studentID` $\\rightarrow$ `(name, dorm, room, fee)`\n","\n","These are of course redundant, with the first two dependencies implied by the third. \n","\n","The following rules can be used to simplify a set of dependencies to just the *non-redundant* ones we need for normalization: \n","\n","- **If A $\\rightarrow$ (B, C), then A $\\rightarrow$ B and A $\\rightarrow$ C.**   \n","  *This is the **decomposition** rule.*\n","- **If A $\\rightarrow$ B and A $\\rightarrow$ C, then A $\\rightarrow$ (B, C).**   \n","  *This is the **union** rule.*\n","- **If (A,B) $\\rightarrow$ C, then we cannot assume that A $\\rightarrow$ C or that B $\\rightarrow$ C.**  \n","  *This is less of a rule than a warning.*\n","\n","So, after capturing all the dependencies and then simplifying to just the essential ones, we find only one dependency, with every column dependent on the primary key (and only the primary key), then the table is fully normalized. \n","\n","> We say a table is in **Domain Key Normal Form (DKNF)** when all functional dependencies are on the primary key and only the primary key. There is no way to normalize beyond that. \n","\n","### **What's an Anomaly?**\n","We learned about anomalies as part of Data Integrity in Lesson 4. Anomalies are violations of referential integrity constraints caused by adding, updating, or deleting data. \n","- **insertion anomaly**: adding a new row to a table causes a foreign key to become ambiguous\n","- **update anomaly**: editing data in a row causes a foreign key to become invalid or ambiguous\n","- **deletion anomaly**: deleting a row triggers a referential integrity violation\n","\n","Generally, most anomalies reduce down one or more of the following bugs:\n","- a fact is defined in more than one place (and can become inconsistent)\n","- a key reference has a typo so that it doesn't match the intended primary key\n","- a row has been deleted, making any references to it invalid\n","- a function or other calculation makes an invalid assumption about the ordering of the rows or columns of the table. \n","\n","If it is possible for any of these things to happen then you need to reconsider your system design. Note that normalization only addresses the first three bugs. If the fourth bug is present then look for a more capable app programmer. That's a rookie mistake that can be fixed with a `SELECT` query. \n","\n","\n","### **1st Normal Form (1NF)**\n","\n","A table in first normal form has\n","- a primary key column (with no duplicates)\n","- no multivalued columns (lists of values)\n","- no repeating groups (of row values)\n","\n","The second and third bullets need a bit of explanation. \n","\n","The following table has a multi-valued column:\n","\n","| name | email addresses |\n","|------| --------------|\n","Barb Ackue |\tbackue@acmesales.com, barb.ackue@gmail.com\n","Buck Kinnear | bkinnear@acmesales.com, buckkinnear2315@hotmail.com\n","\n","**As a general rule if we are tempted to use a plural name for a column then it is likely multivalued.** Presence of a multivalued column is *normalized* away by creating a separate table, with one row per item on the value list:\n","- `Contact(`**`contact_id`**, `name)`\n","- `Contact_Email(`**`contact_email_id`**, `email, usage,`<u>`contact_id`</u>`)`\n","\n","Notice that we used a foreign key to link the two tables together. Foreign keys are always on the \"many\" side of a relationship. Also, we added a `usage` column so we know how the email address is to be used (work, home, spam, etc.). \n","\n","The table below has a repeating group of rows:\n","\n","| name | email |\n","|------| --------------|\n","| Barb Ackue |\tbackue@acmesales.com |\n","|             | barb.ackue@gmail.com |\n","| Buck Kinnear | bkinnear@acmesales.com |\n","|               | buckkinnear2315@hotmail.com |\n","\n","Here the assumption is that the names carry over (repeat) from one row to the next *unless* overwritten by a new name. This does get around the multivalued column but it also makes it so that we can't sort the rows by name without messing up the meaning. Also, what is the primary key of this table? It's pretty dicey all around. \n","\n","**If we have to know the value of the row (column) immediately before the current row (column) then we have a repeating group.**\n","The simplest solution to a repeating group bug is to fill in the blanks and then create a proper primary key. The data will have lots of redundancies but at least it will be 1NF. A *better* solution is the same as for the multivalued column bug: \n","- `Contact(`**`contact_id`**, `name)`\n","- `Contact_Email(`**`contact_email_id`**, `email, usage,`<u>`contact_id`</u>`)`\n","\n","### **2nd Normal Form (2NF)**\n","A table is in second normal form if:\n","- it is already in 1NF\n","- there are no dependencies on just part of the primary key\n","\n","This rule only really comes into play if the table has a **composite primary key** (with multiple columns). If any of the nonkey columns can be determined with a subset of the primary key columns then we have a 2NF violation. \n","\n","**Let (A,B) be a composite key for a table. If B $\\rightarrow$ C for some other column(s) C then the table violates 2NF.** The fix is to create a new table for the B $\\rightarrow$ C relationship, with B as the primary key: \n","- `Table1(`**`A,B`**,`D,E F)`\n","- `Table2(`**`B`**,`C)`\n","\n","Note that we removed column C from `Table1` because it can be looked up from `Table2`\n","\n","**Heads up:** It is possible to have dependencies *within* a composite key. The fix is the same. \n","\n","### **3rd Normal Form (3NF)**\n","A table is in third normal form if\n","- it is in 2NF\n","- there are no dependencies among the nonkey columns\n","\n","**This form comes about because of *transitive* dependencies like A $\\rightarrow$ B $\\rightarrow$ C. Here A is the primary key and B and C are nonkey columns.** The fix is to create a new table for the B $\\rightarrow$ C dependency:\n","- `Table1(`**`A`**,`B,D,E F)`\n","- `Table2(`**`B`**,`C)`\n","\n","This looks very similar to the 2NF fix except that B is not a primary key column. \n","\n","### **Boyce Codd Normal Form (BCNF)**\n","\n","A table is in BCNF if:\n","- it is 3NF\n","- every determinant (on the left of the arrows) is a candidate key\n","\n","Almost always a table in 3NF is also BCNF. However, let's say that we have a composite primary key (A,B) and that there exists a nonkey column C such that C $\\rightarrow$ B. Then while (A,B) may look like a good primary key, (A,C) is better. \n","\n","**BCNF is only in play if there are multiple composite candidate keys *and the wrong one is used as the primary key*.** The fix is to switch to the new primary key. In some cases that may require splitting the table into two or more smaller tables, but we'll leave that for another time. \n","\n","### **4th Normal Form (4NF)**\n","Fourth normal form deals with multivalued dependencies, where a column narrows the scope of another column to a consistent subset. The notation is a little odd:  \n","**determinant $\\twoheadrightarrow$ dependent**\n","\n","The purpose is to pick up hidden repeating fields in the data. Going back to the email address example, consider the following table:\n","\n","|eid | name | email | usage | \n","|---|------| --------------|---|\n","| 1 | Barb Ackue |\tbackue@acmesales.com | work |\n","| 1 | Barb Ackue | barb.ackue@gmail.com | home |\n","| 2 | Buck Kinnear | bkinnear@acmesales.com | work |\n","| 2 | Buck Kinnear | buckkinnear2315@hotmail.com | home |\n","\n","Each time we refer to Barb Ackue we are also referring to her two email addresses. That is a multivalued dependency:\n","\n","**`eid` $\\twoheadrightarrow$ `email`**\n","\n","The solution is to break this into two tables, one for the name and the other for emails:\n","- `Employee(`**`eid`**,`name)`\n","- `Contact(`**`contact_id`**,`email,usage`,<u>`eid`</u>`)`\n","\n","### **Even Higher Normal Forms**\n","\n","In our quest to be even more sure that we will never trigger an anomaly we can go to 5NF, and even 6NF. \n","\n","The final and last normal form is DKNF, which we introduced at the beginning of this section. Unfortunately, there is no set way to redesign a table to always be DKNF. Instead we just have to guess and then check that \n","> \"... all functional dependencies are on the primary key and only the primary key.\" \n","\n","**Fortunately, however, about 99.99% of the time a table in 3NF is also in DKNF.** Leave the remaining edge cases for the hardcore data engineers to figure out. (Though, we will see an example of 4NF normalization in a bit.)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DKpvT0vaTrwH"},"source":["---\n","## **Movies Tonight: A Case Study**\n","\n","This is the start of a 4 part case that will run through Lesson 8. \n","\n","### **A very old-school web app**\n","\n","Movies Tonight was an ancient web app built as tech demo in the days before broadband, CSS, web services, ReST APIs, JSON, and all the other technologies we now take for granted. It was designed to show what a rich user interface could look like once we had all of those things. \n","\n","> For those who may be wondering ... Yes, your instructor built the app over a weekend before a Tuesday morning class. And yes, the design is truly hideous. \n","\n","![Movies Tonight UI](https://github.com/christopherhuntley/BUAN6510/raw/master/img/L5_Movies_Tonight_UI.png)\n","\n","**Through some sort of Internet miracle, [the app still works](http://christopherhuntley.github.io/movies-tonight).** It provides information about every movie shown in Riverside, California, on Thanksgiving 1996. The code is ancient –– Javascript was just 2 years old at the time –– and won’t work in some modern browsers. It should work fine in Chrome and Firefox, however. Try it out to get a feel for the basic flow. \n","\n","While the web design was only barely passable, **the relevance to table design is found in the source code**, which included all the data in a compressed format and parsers used to break it out into usable data records (about movies, theaters, and shows). The idea was that the javascript would be generated by a webserver each time the page was loaded. Then the user would continue on without ever needing to refresh the page. Everything on the screen was *generated* in Javascript, which was truly radical idea at the time but is how most web pages are designed today. \n","\n","![Movies Tonight Source](https://github.com/christopherhuntley/BUAN6510/raw/master/img/L5_Movies_Tonight_Source.png)\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2N12wTI9c9Pn"},"source":["### **The Data, in Three Formats**\n","The data is downloadable as an [MS Excel file](https://github.com/christopherhuntley/ba510-movies-tonight/blob/master/movies.xls). (You may want to do that before moving on.)\n","\n","![Movies Tonight Data in Excel](https://github.com/christopherhuntley/ba510-movies-tonight/raw/master/img/img1.png)  \n","\n","The file has denormalized data in three tabs/sheets:  \n","- **Format 1** is a classic 1960s era mainframe data layout, designed to minimize the number of characters used in the file without using any numerical ids (which can hard to debug by hand). Each record is on a line and is one of three types (M, S, and T). Depending on the record type, the last field may be repeated if there are multiple values, making the # of fields variable (even when the record type doesn’t change).\n","\n","![MT format 1](https://github.com/christopherhuntley/BUAN6510/raw/master/img/L5_Movies_Tonight_format1.png)\n","\n","\n","- **Format 2** is a slightly different arrangement, again with three record types. This time the repeated fields are split into separate records. To conserve characters in the file, fields are left blank if the values are the same in the record above it.\n","\n","![MT format 2](https://github.com/christopherhuntley/BUAN6510/raw/master/img/L5_Movies_Tonight_format2.png)\n","\n","- **Format 3** combines all three record types into a single record, at the cost of being extremely verbose and redundant. Notice how many rows the sheet has! Each record represents a single **movie credit** within a single **movie showing** at a given time at a **single theater**. (Read that three times to be sure you understand before going on.)  \n","\n","![MT format 3](https://github.com/christopherhuntley/BUAN6510/raw/master/img/L5_Movies_Tonight_format3.png)\n","\n","> **Take a moment to think about which of the three formats you might want to use if you were sending 10 billion rows of data over the internet (or a few thousand rows over 1996 dial-up internet). Then think about which one you would want to use to train a machine learning model.** \n","\n","### **Normalizing to 1NF**\n","\n","Of the three formats, the only one that can be made 1NF as a single table  is Format 3. The other two are the very definition of repeating fields. \n","\n","So, let's start with the following table:  \n","`Dataset(`**`dataset_id`**, `tname, location, phone, mtitle, showtime,rating, ccode, cname)`\n","\n","Better yet, let's go with this one, discovered after inspecting the data for repeating patterns (i.e., compostie keys):  \n","`Dataset(`**`tname, mtitle, showtime, ccode, cname`**, `location, phone, rating)`\n","\n","### **Normalizing to 2NF and 3NF**\n","\n","2NF and 3NF require us to *normalize out* any functional dependencies that are not on the full primary key. We find two:\n","- `tname` $\\rightarrow$ (`location`, `phone`)\n","- `mtitle` $\\rightarrow$ `rating`\n","\n","The fix is to break the data into three tables:\n","- `Dataset(`**`tname, mtitle, showtime, ccode, cname`**`)`\n","- `Theaters(`**`mtitle`**, `location, phone)`\n","- `Movies(`**`mtitle`**, `rating)`\n","Note that when removed the dependents (columns on the right sides of the arrows) from the `Dataset` table. That leaves the `Dataset` table with a massive primary key that includes every remainingcolumn. \n","\n","That just can't be right. We're going to have to keep looking. \n","\n","### **Normalizing to BCNF and 4NF**\n","Since there is only one primary key for the `Dataset` table, **we can ignore BCNF.**\n","\n","However, we do find a multivalued dependency to work with. Each movie, no matter how many times it is shown, always has the same movie credits. In other words:  \n","**`mtitle` $\\twoheadrightarrow$ (`ccode`,`cname`)**\n","\n","We can use this to create yet another new table, called `Credits`, leaving us with four tables:\n","- `Dataset(`**`tname, mtitle, showtime`**`)`\n","- `Theaters(`**`mtitle`**, `location, phone)`\n","- `Movies(`**`mtitle`**, `rating)`\n","- `Credits`(**<u>`mtitle`</u>,`ccode, cname`**`)`\n","\n","Note that `mtitle` is a foreign key in the `Credits` table. It's also of course a primary key field. (Yes, that's totally possible.)  \n","\n","### **Final Cleanup**\n","\n","The `Dataset` table doesn't seem right. It's too generic. If we think hard about what each `Dataset` row represents, we will arrive at the concept of a *show* or perhaps a *showing*. Also, we will realize that the `mtitle` and `tname` columns are actually foreign key references to movies and theaters. This suggests a couple of changes to the table definition:\n","- `Shows(`**<u>`tname`</u>,<u>`mtitle`</u>, `showtime`**`)`\n","- `Theaters(`**`mtitle`**, `location, phone)`\n","- `Movies(`**`mtitle`**, `rating)`\n","- `Credits`(**<u>`mtitle`</u>,`ccode, cname`**`)`\n","\n","**Finally, let's adopt best practice and use surrogate keys for all of the tables. This leaves us with:**\n","- `Shows(`**`showid`**`, showtime,`<u>`theaterid`</u>`, `<u>`movieid`</u>`)`\n","- `Theaters(`**`theaterid`**`, tname, location, phone)`\n","- `Movies(`**`movieid`**`, mtitle, rating)`\n","- `Credits`(**`creditid`**`, ccode, cname, `<u>`movieid`</u>)`\n","\n","We will come back to this design in Lesson 6, where we will find that we should add *one more* table.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"www2vN5LTlDo"},"source":["---\n","## **PRO TIPS: How to handle SQLite's quirks**\n","\n","- SQL implementation is barely enough\n","- Poor multiuser support\n","- No security features\n","- Only five data types: TEXT, INTEGER, FLOAT, BLOB, and NULL\n","\n","### **Nonstandard Connection Strings**\n","`sqlite:///filepath`\n","\n","`sqlite://`\n","\n","### **`SELECT` and `rowid`**\n","\n","### **Limited Data Types**\n","\n","### **Dates and Times as TEXT**\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"f65_eey7BvoV"},"source":["---\n","## **SQL AND BEYOND: EAV Models and NoSQL**\n","\n","\n","\n","\n"," \n","\n","\n","\n","\n","\n","\n","\n","  \n","\n"," \n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qVL7n_Rys_95"},"source":["---\n","## **Congratulations! You've made it to the end of Lesson 5.**\n","\n","In this lesson our treatment of table design  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"wEkhlPF5A9w1"},"source":["## **On your way out ... Be sure to save your work**.\n","In Google Drive, drag this notebook file into your `BUAN6510` folder so you can find it next time."]}]}